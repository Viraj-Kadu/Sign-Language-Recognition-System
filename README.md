# ABSTRACT

Sign language serves as a crucial mode of communication for the deaf and hard- of-hearing community, yet barriers in communication with the hearing population persist. This project presents a Sign Language Recognition System utilising machine learning techniques to bridge this gap, enhancing accessibility and inclusivity. The implementation showcases the potential of machine learning in advancing assistive technologies, offering a practical solution to improve communication for the deaf and hard-of-hearing community. Future enhancements aim to incorporate advanced deep learning algorithms and expand the gesture database to cover more sign languages and dialects, further increasing the systemâ€™s utility and reach.This project introduces a Sign Language Recognition System leveraging machine learning frameworks such as TensorFlow and Scikit Learn to mitigate these challenges and promote inclusivity. Instead of convolutional neural networks, the system employs MediaPipe, a robust framework for real-time hand and body motion tracking, to interpret and translate sign language gestures into textual or spoken language in real-time. Trained on an personal dataset of various signs and gestures.



